# Encoder-only Mask Transformer (EoMT) - Zero-Shot Segmentation

This repository contains experiments with the **Encoder-only Mask Transformer (EoMT)** for zero-shot image segmentation.

<img width="539" height="605" alt="EomT Pipeline Comparison" src="https://github.com/user-attachments/assets/a7a2f403-764e-4a94-80f3-186ee4253460" />

## Overview

EoMT demonstrates that a standard Vision Transformer (ViT) encoder can be leveraged as a segmentation model without explicit mask supervision. This repository provides examples of zero-shot segmentation using pretrained models.

<img width="512" height="663" alt="Example EoMT Segmentation using ViT and DinoV2" src="https://github.com/user-attachments/assets/d7f6a5bd-a442-433d-87d5-97c8f9fffe27" />

If you use this code, please cite the original paper:
Kerssies et al., "Your ViT is Secretly an Image Segmentation Model," CVPR 2025
- https://github.com/tue-mps/eomt.git
- https://arxiv.org/abs/2503.19108
